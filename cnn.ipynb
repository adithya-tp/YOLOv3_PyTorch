{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the different layers of YOLO from the .cfg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The read_lines_cfg function:\n",
    "\n",
    "    This function simply returns all the lines in the cfg file after some preprocessing. \n",
    "    The preprocessing steps include the following :\n",
    "    \n",
    "    1. Removing the leading (lstrip()) and trailing (rstrip()) whitespaces.\n",
    "    2. Appending a line only if it is not a comment(\"begins with a '#'\")\n",
    "    3. Appending a line only if it  not empty.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines_cfg(file):\n",
    "    #opening given file in read mode\n",
    "    with open(file=file, mode='r') as yolo:\n",
    "        lines = [(line.lstrip()).rstrip() for line in yolo if (line[0] != '#' and not line is '\\n')]\n",
    "        return lines\n",
    "cfg_lines = read_lines_cfg('yolo_v3/yolov3_cfg/yolov3.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store each layer separately in the \"layers\" list\n",
    "    \n",
    "    We now need to store the information about each layer in a dictionary. The dictionary of info\n",
    "    about each layer is then added to a list. This shall be later used to construct the yolo \n",
    "    network according to the specifications laid out in the respective dictionary of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(lines_list):\n",
    "    layer = {}\n",
    "    layers = []\n",
    "    for line in lines_list:\n",
    "        #check for new layer.\n",
    "        if line[0] == \"[\":\n",
    "            #This condition is to prevent an empty dictionary from being added \n",
    "            #before adding the first block.\n",
    "            if len(layer) != 0:\n",
    "                layers.append(layer)\n",
    "                layer = {}\n",
    "            #Get the value inside square brackts that tells the type of layer we are dealing with.\n",
    "            layer_type = line[1:-1]\n",
    "            layer[\"layer_type\"] = layer_type\n",
    "        else:\n",
    "            #getting the attribute of the layer_type and value for each atrribute.\n",
    "            attrib, val = line.split(\"=\")\n",
    "            #removing the trailing and leading whitespaces for the key and value respectively. \n",
    "            layer[attrib.rstrip()] = val.lstrip()\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_list = get_layers(cfg_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Code up the building blocks\n",
    "\n",
    "### These class definitions will be later used to construct the YOLO v3 network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The Convolutional Layer from the cfg file could also comprise of batchNorm and activation layers as well. \n",
    "    Therefore we need a function which creates a module containing the convolutional, the batchNorm and the \n",
    "    activation layer. The nn.Sequential class would be the module containing the layers, and it ensures the\n",
    "    sequential execution of the layers that it encapsulates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Building-Block Functions for \"Convolution\" and \"UpSample\"\n",
    "\n",
    "    PyTorch already has inbuilt support for Convolution and Upsample Layers. \n",
    "    Therefore we dont need to create classes for these layers since they already \n",
    "    have class definitions which inherit from nn.Module. \n",
    "    \n",
    "    We simply need to create functions that create and return a \"layer module\"\n",
    "    for the respective layer, tailored to the specification mentioned in the \n",
    "    dictionary for that layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Function to create the convolutional Module\n",
    "\n",
    "    1. The function takes in the dictionary containing information about the particular layer.\n",
    "    This includes:\n",
    "        a. Values of number of filters, kernel_size, stride.\n",
    "        b. Whether the conv \"module\" has a BatchNorm Layer.\n",
    "    \n",
    "    2. The function also takes in the number of filters in the previous layer. This is the \n",
    "       value that the \"in_channels\" attribute of the nn.Conv2D method takes in.\n",
    "    \n",
    "    3. Index which indicates the position of the given convolutional layer among the \n",
    "       layers of the yolo net in chronological order.\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_module(info_dict, prev_filters, index):\n",
    "    filters = int(info_dict[\"filters\"])\n",
    "    kernel_size = int(info_dict[\"size\"])\n",
    "    stride = int(info_dict[\"stride\"])\n",
    "    \n",
    "    #for every convolution layer in yolo-tiny v3, pad = 1 and this implies \"same\" padding\n",
    "    \"\"\"\n",
    "    \"same\" padding : the amount of padding applied so that the height and width\n",
    "                     of the output feature map (resulting from the conv2D operation)\n",
    "                     is the same as the input height and width\n",
    "    \"\"\"\n",
    "    \n",
    "    #the value of padding that accomplishes this task (can be derived from simple convolution arithmetic)\n",
    "    padding = (kernel_size - 1) // 2\n",
    "    \n",
    "    #batchNorm already contains a bias term by definition. \n",
    "    #Therefore, bias is set to false if conv layer contains a batchNorm layer.\n",
    "    #It's almost like english!\n",
    "    bias = False if \"batch_normalize\" in info_dict else True\n",
    "    \n",
    "    #creating the conv_layer\n",
    "#     print(prev_filters, filters, kernel_size, stride, padding, bias)\n",
    "    conv_layer = nn.Conv2d(prev_filters, filters, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "    #let us now initialize an nn.Sequential class object\n",
    "    #that will store all the layers we created into this module\n",
    "    conv_module = nn.Sequential()\n",
    "    conv_module.add_module(\"Conv_Layer{}\".format(index), conv_layer)\n",
    "    \n",
    "    #check for batchNorm since every convolution layer does not have a batchNorm layer\n",
    "    #We can do this by checking the bias for the convolutional layer.\n",
    "    if not bias:\n",
    "        batchNorm_layer = nn.BatchNorm2d(filters)\n",
    "        conv_module.add_module(\"BatchNorm_Layer{}\".format(index), batchNorm_layer)\n",
    "    \n",
    "    #activation for the conv layer could be either \"linear\" or \"leaky relu\". \n",
    "    #the following condition checks for this\n",
    "    if info_dict[\"activation\"] == \"leaky\":\n",
    "        activation_layer = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        conv_module.add_module(\"Activation_Layer{}\".format(index), activation_layer)\n",
    "    \n",
    "    return (filters, conv_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Function to create the upsample module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_module(info_dict, index):\n",
    "    \n",
    "    scale_factor = info_dict[\"stride\"]\n",
    "    upsample_layer = nn.Upsample(scale_factor=scale_factor, mode=\"bilinear\")\n",
    "    \n",
    "    #instantiate an object of nn.Sequential class to encapsulate the upsample layer\n",
    "    upsample_module = nn.Sequential()\n",
    "    upsample_module.add_module(\"Upsample_Layer{}\".format(index), upsample_layer)\n",
    "    \n",
    "    return upsample_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Function to create the shortcut module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortcut_module(info_dict, index):\n",
    "    \n",
    "    shortcut_from = info_dict[\"from\"]\n",
    "    shortcut_layer = SHORTCUT_layer(index, shortcut_from)\n",
    "    shortcut_module = nn.Sequential()\n",
    "    shortcut_module.add_module(\"Shorcut_Layer{}\".format(index), shortcut_layer)\n",
    "\n",
    "    return shortcut_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHORTCUT_layer(nn.Module):\n",
    "    def __init__(self, index, shortcut_from):\n",
    "        super(SHORTCUT_layer, self).__init__()\n",
    "        self.index = index\n",
    "        self.shortcut_from = shortcut_from\n",
    "    \n",
    "    def forward(self, output_tracker):\n",
    "        return output_tracker[self.index - 1] + output_tracker[self.index + self.shortcut_from]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Building-Block Classes for Route and YOLO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Route Block:\n",
    "    Here we wish to perform the following tasks:\n",
    "        \n",
    "        1. Create a function to count the number of filters that the route block concatenates\n",
    "        2. Create a class with route block functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "route_filters_count takes in:\n",
    "    1. info_dict - info_dict for the route block\n",
    "    2. index - the position of the route block int the net\n",
    "    3. output_filters - list that keeps track of the number of output filters from all blocks\n",
    "\"\"\"\n",
    "def route_filters_count(info_dict, index, output_filters):\n",
    "    num_filters = 0\n",
    "    layers = info_dict[\"layers\"].split(\",\")\n",
    "    \n",
    "    #since the route module could have either one or two layers to route,\n",
    "    #the following try block will check for this.\n",
    "    try:\n",
    "        layer0, layer1 = int(layers[0]), int(layers[1])\n",
    "    except:\n",
    "        layer0, layer1 = int(layers[0]), 0\n",
    "    \n",
    "    print(layer0, layer1)\n",
    "        \n",
    "    #values for layer1 is always zero for yolo-v3 tiny and layer2 is either >=0\n",
    "    #the following is only for the purpose of appending to the output_filters list.\n",
    "    \n",
    "    #these cases dont arise in yolo-tiny v3, but could possibly arise in yolo v3.\n",
    "    if layer0 > 0:\n",
    "        layer0 = layer0 - index\n",
    "       \n",
    "    if layer1 > 0:\n",
    "        layer1 = layer1 - index\n",
    "        \n",
    "    #check if layers contains only one value    \n",
    "    if layer1 < 0:\n",
    "        num_filters = output_filters[index + layer0] + output_filters[index + layer1]\n",
    "    \n",
    "    else:\n",
    "        num_filters = output_filters[index + layer0]\n",
    "\n",
    "    return (num_filters, layer0, layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ROUTE layer class def\n",
    "    The route layer class needs to be defined by us, since PyTorch does not provide\n",
    "    support for the route layer. The route layer is initialized with the values\n",
    "    of layer0 and layer1(if any). The forward method, finds the ouput that the \n",
    "    route block has to route from previous layers.\n",
    "    \n",
    "    To accomplish this, the outputs of different layers in the forward pass\n",
    "    are tracked in the output_tracker. This output_tracker is passed \n",
    "    when finding which outputs to route, (and possibly concatenate). \n",
    "    \n",
    "    The output that is to be routed is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROUTE_layer(nn.Module):\n",
    "    def __init__(self, index, layer0, layer1=None):\n",
    "        super(ROUTE_layer, self).__init__()\n",
    "        self.index = index\n",
    "        self.layer0 = layer0\n",
    "        if layer1 is None:\n",
    "            self.len_layers = 1\n",
    "            pass\n",
    "        else:\n",
    "            self.len_layers = 2\n",
    "            self.layer1 = layer1\n",
    "    \n",
    "    def forward(self, output_tracker):\n",
    "        if self.len_layers == 1:\n",
    "            x = output_tracker[self.index + layer0]\n",
    "        else:\n",
    "            #joining the two maps along the depth dimension using torch's cat function \n",
    "            x = torch.cat((output_tracker[self.index+self.layer0], output_tracker[self.index+self.layer1]), 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a ROUTE building block\n",
    "    We now bring to together the function that counts the number of output filters and the \n",
    "    Class that instantiates the route layer. The following function first finds the number\n",
    "    of filters, and layers values for the route layer. These \"layers\" values are first used to\n",
    "    create an object of the route layer. \n",
    "    \n",
    "    This route layer is bundled into a route module with the nn.Sequential class and is returned\n",
    "    to the module_list building function along with the number of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_module(info_dict, index, output_filters):\n",
    "    \n",
    "    \n",
    "    filters, layer0, layer1 = route_filters_count(info_dict, index, output_filters)\n",
    "    if layer1 == 0:\n",
    "        route_layer = ROUTE_layer(index, layer0)\n",
    "    else:\n",
    "        route_layer = ROUTE_layer(index, layer0, layer1)\n",
    "    \n",
    "    route_module = nn.Sequential()\n",
    "    route_module.add_module(\"Route_Module{}\".format(index), route_layer)\n",
    "    return (filters, route_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2  YOLO Block:\n",
    "\n",
    "    Following along the lines of the Route Block, we will:\n",
    "        1. Create a function to choose the anchors to use for the YOLO block\n",
    "        2. Create a class for the YOLO Block that inherits from nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_anchors(info_dict, index):\n",
    "    #get the mask values from info_dict\n",
    "    mask = [int(x) for x in info_dict[\"mask\"].split(\",\")]\n",
    "\n",
    "    anchors = [int(x) for x in info_dict[\"anchors\"].split(\",\")]\n",
    "    masked_anchors = []\n",
    "    for position in mask:\n",
    "        #the tuple of anchor values we need are at [2*position] and [2*position  + 1]\n",
    "        #Eg, if mask = 0, we need a tuple with values at [2*0] and [2*0 + 1] = [0,1]\n",
    "        masked_anchors.append((anchors[2*position], anchors[2*position + 1]))\n",
    "    \n",
    "    print(index, masked_anchors)\n",
    "    return masked_anchors    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLO_layer layer definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_layer(nn.Module):\n",
    "    def __init__(self, masked_anchors):\n",
    "        super(YOLO_layer, self).__init__()\n",
    "        self.masked_anchors = masked_anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function that brings together get_yolo_anchors and YOLO_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_module(info_dict, index):\n",
    "    \n",
    "    yolo_layer = YOLO_layer(get_yolo_anchors(info_dict, index))\n",
    "    yolo_module = nn.Sequential()\n",
    "    yolo_module.add_module(\"YOLO_layer{}\".format(index), yolo_layer)\n",
    "    \n",
    "    return yolo_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bringing Section 2 together\n",
    "\n",
    "    We can now define a function that creates an nn.ModuleList that stores all nn.Module objects.\n",
    "    These nn.Module objects would contain the building blocks that we defined earlier.\n",
    "    The function accepts the layers_list that we created in section 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_module_list(layers_list):\n",
    "    module_list = nn.ModuleList() #stores all the nn.Module objects \n",
    "    prev_filters = 3 #since we start out with color images\n",
    "    output_filters = []\n",
    "    \n",
    "    #the info about the neural net itself is contained in the first dictionary \n",
    "    #of the layers_list, and is not really a \"layer\"\n",
    "    yolo_info = layers_list[0]\n",
    "    \n",
    "    for index, layer_dict in enumerate(layers_list[1:]):\n",
    "        \n",
    "        if layer_dict[\"layer_type\"] == \"convolutional\":\n",
    "            filters, module = conv_module(layer_dict, prev_filters, index)\n",
    "        \n",
    "        elif layer_dict[\"layer_type\"] == \"upsample\":\n",
    "            module = upsample_module(layer_dict, index)\n",
    "        \n",
    "        elif layer_dict[\"layer_type\"] == \"route\":\n",
    "            filters, module = route_module(layer_dict, index, output_filters)\n",
    "        \n",
    "        elif layer_dict[\"layer_type\"] == \"shortcut\":\n",
    "            module = shortcut_module(layer_dict, index)\n",
    "            \n",
    "        elif layer_dict[\"layer_type\"] == \"yolo\":\n",
    "            module = yolo_module(layer_dict, index)\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "        module_list.append(module)        \n",
    "        prev_filters = filters\n",
    "        output_filters.append(filters)\n",
    "#     print(prev_filters)\n",
    "    print(output_filters)\n",
    "    return (yolo_info, module_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 [(116, 90), (156, 198), (373, 326)]\n",
      "-4 0\n",
      "-1 61\n",
      "94 [(30, 61), (62, 45), (59, 119)]\n",
      "-4 0\n",
      "-1 36\n",
      "[32, 64, 32, 64, 64, 128, 64, 128, 128, 64, 128, 128, 256, 128, 256, 256, 128, 256, 256, 128, 256, 256, 128, 256, 256, 128, 256, 256, 128, 256, 256, 128, 256, 256, 128, 256, 256, 512, 256, 512, 512, 256, 512, 512, 256, 512, 512, 256, 512, 512, 256, 512, 512, 256, 512, 512, 256, 512, 512, 256, 512, 512, 1024, 512, 1024, 1024, 512, 1024, 1024, 512, 1024, 1024, 512, 1024, 1024, 512, 1024, 512, 1024, 512, 1024, 255, 255, 512, 256, 256, 768, 256, 512, 256, 512, 256, 512, 255, 255, 256, 128, 128, 384, 128, 256, 128, 256, 128, 256, 255]\n"
     ]
    }
   ],
   "source": [
    "info, mod_list=create_module_list(layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "# mod_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the YOLO net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        We will now use the module_list that we constructed in section 3 to build up the\n",
    "        class for the YOLO network. We would also need to workout the forward pass for the\n",
    "        YOLO net. \n",
    "        \n",
    "        The net itself inherits nn.Module class, like every one of its individual\n",
    "        layers. This makes sense, since the YOLO net can be thought of as a huge layer/function.\n",
    "        That is indeed the case, since any neural net is a composition of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv3(nn.Module):\n",
    "    def __init__(self, config_filename):\n",
    "        super(YOLOv3, self).__init__()\n",
    "        self.layers_list = read_lines_cfg(config_filename)\n",
    "        self.mod_list = create_module_list(self.layers_list)\n",
    "    \n",
    "    def forward(self, x, cuda):\n",
    "        output_tracker = {}\n",
    "        \n",
    "        for index, layer in enumerate(self.layers_list[1:]):\n",
    "            \n",
    "            if layer[\"type\"] == \"convolutional\":\n",
    "                out = self.module_list[index](x)\n",
    "                \n",
    "            elif layer[\"type\"] == \"upsample\":\n",
    "                out = self.module_list[index](x)\n",
    "            \n",
    "            elif layer[\"type\"] == \"route\":\n",
    "                out = self.module_list[index](output_tracker)\n",
    "            \n",
    "            elif layer[\"type\"] == \"shortcut\":\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function to transform the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mod_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, layer in enumerate(layers_list):\n",
    "#     if layer[\"layer_type\"] == \"convolutional\":\n",
    "#     if layer[\"layer_type\"] == \"yolo\":\n",
    "#         anchors = [int(x) for x in layer[\"anchors\"].split(\",\")]\n",
    "#         print(anchors)\n",
    "#         print(layer[\"layers\"].split(\",\"))\n",
    "#         print(index, layer[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
